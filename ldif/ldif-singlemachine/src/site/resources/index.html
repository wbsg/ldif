<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html><head>
  <title>LDIF - Linked Data Integration Framework</title>

  
  
  <style>
body { background: white; color: black; font-family: sans-serif; line-height: 1.4em; padding: 2.5em 3em; margin: 0; }
:link { color: #00c; }
:visited { color: #609; }
a:link img { border: none; }
a:visited img { border: none; }
h1, h2, h3 { background: white; color: #800; }
h1 { font: 170% sans-serif; margin: 0; }
h2 { clear: both; font: 140% sans-serif; margin: 1.5em 0 -0.5em 0; }
h3 { font: 120% sans-serif; margin: 1.5em 0 -0.5em 0; }
h4 { font: bold 100% sans-serif; }
h5 { font: italic 100% sans-serif; }
h6 { font: small-caps 100% sans-serif; }
.hide { display: none; }
pre { background: #fff6bb; font-family: monospace; line-height: 1.2em; padding: 1em 2em; }
dt { font-weight: bold; margin-top: 0; margin-bottom: 0; }
dd { margin-top: 0; margin-bottom: 0; }
code, tt { font-family: monospace; }
ul.toc { list-style-type: none; }
ol.toc li a { text-decoration: none; }
.note { color: red; }
#header { border-bottom: 1px solid #ccc; }
#logo { float: right; }
#authors { clear: right; float: right; font-size: 80%; text-align: right; }
#content { clear: both; margin: 2em auto 0 0; text-align: justify }
#download, #demo { float: left; font-family: sans-serif; margin: 1em 0 1.5em; text-align: center; width: 50%; }
#download h2, #demo h2 { font-size: 125%; margin: 1.5em 0 -0.2em 0; }
#download small, #demo small { color: #888; font-size: 80%; }
#footer { border-top: 1px solid #ccc; color: #aaa; margin: 2em 0 0; }
@media Print {
* { font-size: 92%; }
body { padding: 0; line-height: 1.2em; }
#content { margin: 0; width: 100%; }
}
@media Aural {
h1 { stress: 20; richness: 90; }
h2 { stress: 20; richness: 90; }
h3 { stress: 20; richness: 90; }
.hide { speak: none; }
dt { pause-before: 20%; }
pre { speak-punctuation: code; }
}
  .Stil1 {color: #FF0000}
  </style>
  
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

</head><body>
<div id="logo"> <a href="http://www.fu-berlin.de/"><img src="img/fu-logo.gif" alt="Freie Universität Berlin Logo"></a></div>

<div id="header">
<h1 style="font-size: 250%;">LDIF - Linked Data Integration Framework<br>
</h1>
<div id="tagline">A component for building Linked Data applications <br>
</div>
<div id="authors"><a href="mailto:aschultz@mi.fu-berlin.de">Andreas
Schultz</a><br>
<a href="mailto:andrea.matteini@gmail.com">Andrea Matteini</a><br>
<a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/team/IseleRobert.html">Robert
Isele</a><br>
<a href="http://www.bizer.de/">Chris
Bizer</a><br>
<a href="mailto:chris@beckr.org">Christian Becker</a><br>
</div>
<div id="content">
<p>The LDIF - Framework translates Linked Data from the Web into <br>
a clean, local target representation while keeping track of data
provenance.<br>
LDIF can be used as a data integration component for building Linked
Data<br>
applications. </p>
<div id="download">
<h2>Download LDIF<br>
</h2>
<small>v0.1 (alpha), released TODO</small>
</div>
<h2 id="news">News</h2>
<ul>
  <li><strong>6/28/2011: Version 0.1 released.</strong> This alpha
version provides for translating data that is represented using
different source vocabularies into a single target vocabulary and for
replacing different URIs that refer to the same real-world entity with
a single URI. &nbsp;</li>
</ul>
<h2 id="contents">Contents</h2>
<ol class="toc">
  <li><a href="#about">About LDIF</a></li>
  <li><a href="#components">LDIF components</a></li>
  <li><a href="#quickstart">Quick start</a></li>
  <li><a href="#examples">Example: Using LDIF for integrating Life
Science Data </a></li>
  <li><a href="#performance">Performance Evaluation</a> </li>
  <li><a href="#config">Configuration options</a></li>
  <li><a href="#code">Source code and development</a></li>
  <li><a href="#feedback">Support and Feedback</a></li>
  <li><a href="#related">References</a></li>
</ol>
<h2 id="about"><a name="about"></a>1. About LDIF<br>
</h2>
<p>The <a href="http://linkeddatabook.com/editions/1.0/#htoc23">Web of
Linked Data</a>
grows rapidly and contains data from a wide range of different domains,
including life science data, geographic data, government data, library
and media data, as well as cross-domain datasets such as DBpedia or
Freebase. <a href="http://linkeddatabook.com/editions/1.0/#htoc75">Linked
Data applications</a> that want to consume data from this global data
space face the challenges that:</p>
<ol>
  <li> data sources use a wide range of different RDF vocabularies to
represent data about the same type of entity. </li>
  <li>the
same real-world entities, for instance a person or a place, are
identified with different URIs within different data sources. </li>
</ol>
<p>This usage of different vocabularies as well as the usage of URI
aliases makes it, for instance, very cumbersome for an application
developer to write <a href="http://www.w3.org/TR/rdf-sparql-query/">SPARQL</a>
queries against Web data which originates from multiple sources. In
order to ease using Web data in the application context, it is thus
advisable to translate data to a single target vocabulary (<a href="http://linkeddatabook.com/editions/1.0/#htoc86">vocabulary
mapping</a>) and to replace URI aliases with a single URI on the client
side (<a href="http://linkeddatabook.com/editions/1.0/#htoc87">identity
resolution</a>), before starting to ask SPARQL queries against the
data. </p>
<p>Up-till-now, there have not been any integrated tools that help
application developers with these tasks. With LDIF, we try to fill this
gap and provide an initial version of an open-source Linked Data
Integration Framework that can be used within applications to translate
Web data and normalize URI aliases. </p>
<p>The figure below shows the schematic <a href="http://linkeddatabook.com/editions/1.0/#htoc84">architecture of
Linked Data applications </a>that
implement the Crawling/Data Warehousing Pattern. The figure also
highlights the steps of the data integration process that are currently
supported by LDIF.<br>
<br>
<span class="Stil1"> </span> </p>
<p style="text-align: left; margin-left: 120px;"><img style="border: 1px solid ; width: 650px; height: 501px;" alt="Example-architecture of an integration aware Linked Data application" src="img/ldarchitecture.png"></p>
<p style="text-align: left; margin-left: 120px;">&nbsp;</p>
<h2><a name="components"></a>2. LDIF Components<br>
</h2>
<p>The LDIF Framework consists of the Runtime Environment and a set of
pluggable modules. The pluggable modules are organized in a Data Access
Component, a Data Transformation Component and a Data Output Component.
</p>
<p><img src="img/LDIFcomponents.png" height="92" width="299"></p>
Currently, we have implemented the following modules: <br>
<h3>Data Access: N-Quad Loader<br>
</h3>
<br>
<p>Version 0.1 of LDIF expects input data to be represented as Named
Graphs and be stored in <a href="http://sw.deri.org/2008/07/n-quads/">N-Quad
format</a> in a local directory. The graph URI of each quad is used for
provenance tracking. These graphs themselves can be described in a
specific provenance graph, which is configurable. In this way the final
dataset that is produced by the integration flow still includes all the
provenance information about the sources.<br>
</p>
<h3>Transformation: R2R Data Translation<br>
</h3>
<br>
<p>LDIF employs the <a href="http://www4.wiwiss.fu-berlin.de/bizer/r2r/">R2R Framework</a>
to translate Web data that is represented using terms from different
vocabularies into a single target vocabulary. Vocabulary mappings are
expressed using the <a href="http://www4.wiwiss.fu-berlin.de/bizer/r2r/spec/">R2R Mapping
Language</a>,
a language that provided for simple transformations as well as for more
complex structural transformations and property value transformations
such as normalizing different units of measurement. The syntax of the
R2R Mapping Language is very similar to the query language SPARQL,
which eases the learning curve. The expressivity of the language is
higher than the expressivity provided by the <a href="http://www.w3.org/TR/2004/REC-owl-features-20040210/#s3.2">OWL
Equality and Inequality constructs</a>, making the language capable to
deal with most requirements arise around properly translating data in
real-world use cases. </p>
<p>An overview and examples for mappings are given on the <a href="http://www4.wiwiss.fu-berlin.de/bizer/r2r/">main page</a> of the
R2R Framework.<br>
The <a href="http://www4.wiwiss.fu-berlin.de/bizer/r2r/spec/">specification
and user manual</a> is described in a separate document.<br>
</p>
<h3>Transformation: Silk Identity Resolution </h3>
<p><br>
LDIF employs the <a href="http://www4.wiwiss.fu-berlin.de/bizer/silk/">Silk
Framework</a>
to discover real-world entities that are identified with different URIs
within different data sources. Afterwards, these URI aliases are
replaced with a single URI within the data. Silk is a flexible identity
resolution framework that allows the user to specify identity
resolution heuristics which combine different typs of matchers using
the declarative <a href="http://www4.wiwiss.fu-berlin.de/bizer/silk/spec/">Silk - Link
Specification Language</a>.</p>
<p>An overview and examples can be found on the <a href="http://www4.wiwiss.fu-berlin.de/bizer/silk/">Silk main page</a>.<br>
</p>
<h3 style="text-align: left;">Data Output: Nquad Writer<br>
</h3>
<br>
<p>The N-Quads writer simply dumps the final output of the integration
flow into a single file in N-Quads syntax.<br>
</p>
<h3 style="text-align: left;">Runtime Environment </h3>
<p style="text-align: left;"> The Runtime Environment manages the data
flow between the various stages and the caching of the intermediate
results. Currently there are two execution profiles (implementations)
of the runtime environment:</p>
<ol>
  <li>In-Memory Implementation: Keeps all intermediate results in
memory. Is very fast but scales only depending on the amount of memory
available. </li>
  <li>File-backed Implementation: Uses the <a href="http://project-voldemort.com/">Project Voldemort</a> key-value
store to keep intermediate results. Is slower than the in-memory
implementation but scales to larger amounts of data. <br>
</li>
</ol>

<h3>Next steps for LDIF</h3>
<p>LDIF V0.1 only provides data translation and identity resolution
functionality. Over the next months, we plan to extend LDIF along the
following lines:</p>
<ol>
  <li>Add <strong>Web Data Access Modules</strong> (Linked Data
Crawler, SPARQL Endpoint Reader, Remote RDF File Loader) as well as a
scheduling component which provides for regularly updating the local
input data cache. </li>
  <li>Add a <strong>Data Quality Evaluation and Data Fusion Module</strong>
which allows Web data to be filtered according to different data
quality assessment policies and provides for fusing Web data according
to different fusion methods. </li>
  <li>Implement a <strong>Hadoop Version of the Runtime Environment </strong>in
order to be able to scale to large amounts of input data. Processes and
data will be distributed over a cluster of machines.</li>
  <li><strong>Flexible integration workflow</strong>. Currently the
integration flow is static and can only be influenced by predefined
configuration parameters. We plan to make the workflow and its
configuration more flexible in order to make it easier to include
additional modules that cover other data integration aspects. </li>
</ol>
<p>&nbsp;</p>
<h2 id="quickstart"><a name="quickstart"></a>3. Quick start</h2>
<br>
In order to experiment with LDIF follow these steps:<br>
<ol>
  <li>Download the latest release (download link at the top of this
page)</li>
  <li>Unpack the archive to an arbitrary location</li>
  <li>To run the command line tool type the following in the root
directory of LDIF:<br>
  </li>
</ol>
<pre>bin/run &lt;path-to-ldif-config-file&gt;<br><br>bin\run.bat &lt;path-to-ldif-config-file&gt;<br></pre>
For details about the configuration file and parameters, see <a href="#config">Section 6</a>.
<p>&nbsp;</p>
<h2 id="development"><a name="examples"></a>4. Example: Using LDIF to
integrate Life Science Data </h2>
<br>
<p>To be able to execute&nbsp;the following examples you need to set up
everything as explained under <a href="#quickstart">Quick start</a>.</p>
<p><strong>Example 1:<br>
</strong></p>
<p>This example shows how LDIF is applied to five Life Science datasets from different sources.<br>
</p>
<ul>
  <li>Description of the use case and the data sources:</li>
</ul>
<p style="margin-left: 40px;">The Allen Brain Atlas is a growing
collection of online public resources integrating extensive gene
expression and neuroanatomical data, complete with a novel suite of
search and viewing tools. A number of internal and external life
science data sources provide supplemental information that is
potentially of high interest to Allen Brain Atlas users. By using
Linked Data Integration, these data sources can be brought together to
improve the user experience and eventually assist in serendipitous
discovery.<br>
<br>
Some sources of interest are:<br>
</p>
<ul>
  <ul>
    <li>KEGG Pathway, a collection of pathway maps representing knowledge on the molecular interaction and reaction networks</li>
    <li>PharmGKB, which provides data on gene information, disease and drug pathways, and SNP variants</li>
    <li>Uniprot, which provides information on protein sequence and function<strong></strong><br>
    </li>
  </ul>
</ul>
<ul>
  
  <li>R2R mapping file: <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/mappings/ALL-to-Wiki.r2r.ttl?rev=176428845b9594e28a2f0362916de23cc821502c">ALL-toWiki.r2r.ttl</a>
    <span style="text-decoration: underline;"></span></li>
  <li>Silk Linking Specifications: <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/linkSpecs/ABA-to-Wiki.silk.xml?rev=176428845b9594e28a2f0362916de23cc821502c">ABA-to-Wiki.silk.xml</a>,
    <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/linkSpecs/KEGG-GENES-to-Wiki.silk.xml?rev=176428845b9594e28a2f0362916de23cc821502c">KEGG-GENES-to-Wiki.silk.xml</a>,
    <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/linkSpecs/KEGG-Pathway-to-Wiki.silk.xml?rev=176428845b9594e28a2f0362916de23cc821502c">KEGG-Pathway-to-Wiki.silk.xml</a>,
    <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/linkSpecs/PharmGKB-to-Wiki.silk.xml?rev=176428845b9594e28a2f0362916de23cc821502c">PharmGKB-to-Wiki.silk.xml</a>,
    <a href="http://www.assembla.com/code/ldif/git/nodes/ldif/ldif-singlemachine/src/main/resources/ldif/local/example/test2/linkSpecs/Uniprot-to-Wiki.silk.xml?rev=176428845b9594e28a2f0362916de23cc821502c">Uniprot-to-Wiki.silk.xml</a><span style="text-decoration: underline;"><br>
    </span></li>
  <li>LDIF configuration file:<br>
  </li>
  <pre>&lt;LDIF&gt;<br>  &lt;Properties&gt;test1k.properties&lt;/Properties&gt;<br>  &lt;Sources&gt;sources&lt;/Sources&gt;<br>  &lt;LinkSpecifications&gt;linkSpecs&lt;/LinkSpecifications&gt;<br>  &lt;Mappings&gt;mappings/ALL-to-Wiki.r2r.ttl&lt;/Mappings&gt;<br>  &lt;Output&gt;output1.nq&lt;/Output&gt;<br>&lt;/LDIF&gt;</pre>
  <li>Execution
instructions:</li>
  <ul>
    <li>Change into the LDIF root
dir.</li>
    <li>Under Unix type:</li>
    <pre>bin/run examples/example1/config.xml</pre>
    <li>Under
Windows type:</li>
    <pre>bin\run examples\example1\config.xml</pre>
  </ul>
  
  <li>Example input quads (reduced to two source datasets):<br></li>
</ul>
<pre style="margin-left: 40px;">01: @prefix aba-voc: &lt;http://brain-map.org/gene/0.1#&gt; .<br>02: @prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .<br>03: @prefix uniprot: &lt;http://purl.uniprot.org/core/&gt; . <br>04:&nbsp;<br>05: &lt;file:///aba_mouse_20101010_1000.nq&gt; {<br>06:   &lt;http://brain-map.org/mouse/brain/Oprk1.xml&gt; aba-voc:entrezgeneid "18387" ;<br>07:     aba-voc:gene-aliases _:Ab12290 .<br>08:  _:Ab12290 &lt;http://brain-map.org/gene/0.1#aliassymbol&gt; "Oprk1" .<br>09: }<br>10:<br>11: &lt;file:///datasets/uniprot-organism-human-reviewed-complete_1000.nq&gt; {<br>12:  &lt;http://purl.uniprot.org/uniprot/P61981&gt; rdfs:seeAlso &lt;http://purl.uniprot.org/geneid/18387&gt; .<br>13:   &lt;http://purl.uniprot.org/geneid/7532&gt; uniprot:database "GeneID" .<br>14:   &lt;http://purl.uniprot.org/uniprot/P61981&gt; uniprot:encodedBy &lt;file:///storage/datasets/uniprot-organism-human-reviewed-complete.rdf#_503237333438003B&gt; .<br>15: }<br></pre>

<ul>
  <li>Example output quads:<br>
  </li>
</ul>
<pre style="margin-left: 40px;">01: @prefix smwprop: &lt;http://mywiki/resource/property/&gt; .<br>02: @prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .<br>03: 
04: &lt;file:///aba_mouse_20101010_1000.nq&gt; {<br>05:  &nbsp;&lt;http://brain-map.org/mouse/brain/Oprk1.xml&gt; smwprop:EntrezGeneId "18387"^^xsd:int .<br>06:  &nbsp;&lt;http://brain-map.org/mouse/brain/Oprk1.xml&gt; smwprop:GeneSymbol "Oprk1"^^xsd:string .<br>07: }<br>08: <br>09: &lt;file:///datasets/uniprot-organism-human-reviewed-complete_1000.nq&gt; {  <br>10:   &lt;http://brain-map.org/mouse/brain/Oprk1.xml&gt; smwprop:EntrezGeneId "18387"^^xsd:int .<br>11: }<br></pre>

<p>The example input and output needs some explanation:<br>
</p>
<ul>
  <li>There are two source graphs, each containing data from a different source: From ABA and Uniprot in this example<br>
  </li>
  <li>Both graphs contain data about the same entity:</li>
  <ul>
    <li>In the ABA dataset the URI is <span style="font-family: monospace;">&lt;http://brain-map.org/mouse/brain/Oprk1.xml&gt;</span></li>
    <li>In the Uniprot dataset the URI is <span style="font-family: monospace;">&lt;file:///storage/datasets/uniprot-organism-human-reviewed-complete.rdf#_503237333438003B&gt;</span></li>
  </ul>
  <li>Since they are considered the same entity the URIs in the output
were rewritten and only one of the two URIs is used (the ABA one in
this case).</li>
  <li>In the Uniprot case the <span style="font-family: monospace;">smwprop:EntrezGeneId</span> value was extracted from the URI <span style="font-family: monospace;">&lt;http://purl.uniprot.org/geneid/18387&gt;<span style="font-family: sans-serif;">. </span></span>As you can also see, this URI is not directly connected with the entity in the Uniprot dataset.</li>
  <li>Because the <span style="font-family: monospace;">smwprop:EntrezGeneId</span> value came from both datasets, it is also represented two times in the output. Whereas the <span style="font-family: monospace;">smwprop:GeneSymbol</span> value is derived from the ABA dataset only.<br>
  </li>
</ul>
<h2 id="development"><a name="performance" id="performance"></a>5.
Performance Evaluation</h2>

<p>We regularly carry out performance evaluations. Our test use case
resembles the one of example 1 in section 4 of this document. In order
to measure the performance at different scale we used several samples
which differ in the amount of entities. In the following we present our
setup for the experiments and then give an overview of our results.</p>
<p>Test machine:<br>
</p>
<ul>
  <li>OS – Ubuntu 10.04.2 LTS 64-bit<br>
  </li>
  <li>Intel Core i5-2500K CPU @ 3.30GHz (quadcore)</li>
  <li>16GB of memory</li>
  <li>SATA HD</li>
</ul>LDIF setup:<br>
<ul>
  <li>In-memory storage solution<br>
  </li>
</ul>
<p>Overview of the results:</p>

<table style="text-align: left; width: 1012px; height: 150px;" border="1" cellpadding="2" cellspacing="0">
  <tbody>
    <tr>
      <td style="vertical-align: top; font-weight: bold;">Number of
entities per dataset<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">Number of
quads</td>
      <td style="vertical-align: top; font-weight: bold;">dataset size
on disk (N-Quads format)<br>
      </td>
      <td style="vertical-align: top; font-weight: bold;">runtime (in
mm:ss)</td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: center;">1K<br>
      </td>
      <td style="vertical-align: top; text-align: center;">1M<br>
      </td>
      <td style="vertical-align: top; text-align: center;">150MB<br>
      </td>
      <td style="vertical-align: top; text-align: center;">0:36<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: center;">10K<br>
      </td>
      <td style="vertical-align: top; text-align: center;">7.5M<br>
      </td>
      <td style="vertical-align: top; text-align: center;">1GB<br>
      </td>
      <td style="vertical-align: top; text-align: center;">3:40<br>
      </td>
    </tr>
    <tr>
      <td style="vertical-align: top; text-align: center;">100K<br>
      </td>
      <td style="vertical-align: top; text-align: center;">24M<br>
      </td>
      <td style="vertical-align: top; text-align: center;">4GB<br>
      </td>
      <td style="vertical-align: top; text-align: center;">16:55<br>
      </td>
    </tr>
  </tbody>
</table>
<br>
The memory foot print for the 100k-test was 7.2 GB at maximum. For more details and the latest results please visit our <a href="https://www.assembla.com/spaces/ldif/wiki/Performance_Tests">Performance Testing</a>&nbsp; page.<br>
<p><strong><br>
</strong></p>
<h2 id="configuration"><a name="config"></a>6. Configuration
Options</h2>
<br>
<p>In this section we describe how an LDIF configuration file looks
like and which parameters you can modify to change the runtime
behaviour of LDIF.<br>
</p>
<h3>LDIF configuration file</h3>
<p>LDIF is configured with an XML file, whose current structure is very
simple because the integration flow is static at the moment - something
that will change in future releases. A typical config file looks like
this:<br>
</p>
<pre>&lt;LDIF&gt;<br>  &lt;Properties&gt;test1.properties&lt;/Properties&gt;<br>  &lt;Sources&gt;sources&lt;/Sources&gt;<br>  &lt;LinkSpecifications&gt;linkSpecs&lt;/LinkSpecifications&gt;<br>  &lt;Mappings&gt;mappings/mappings.ttl&lt;/Mappings&gt;<br>  &lt;Output&gt;output.nq&lt;/Output&gt;<br>&lt;/LDIF&gt;</pre>
<p>It has the following elements:<br>
</p>
<ul>
  <li><span style="font-style: italic;">Properties</span>: The path to
a Java properties file for configuration parameters.</li>
  <li><span style="font-style: italic;">Sources</span>: The directory
to the source datasets. This is also the location where provenance data
can be stored. These files must be in <a href="http://sw.deri.org/2008/07/n-quads/">N-Quads</a> format and may
be compressed (.gz, .zip).</li>
  <li><span style="font-style: italic;">LinkSpecifications</span>: The
directory containing the <a href="http://www.assembla.com/wiki/show/silk/Link_Specification_Language">Silk
link specifications</a>.</li>
  <li><span style="font-style: italic;">Mappings</span>: File
containing <a href="http://www4.wiwiss.fu-berlin.de/bizer/r2r/spec/#mappings">R2R
mappings</a>.</li>
  <li><span style="font-style: italic;">Output</span>: The name of the
output dataset with the integrated data.<br>
  </li>
</ul>
<p>All the paths are relative to the config file location. In this case
there is a root directory with the config file and the test1.properties
file in it. Furthermore the following directories would be nested in
the root directory: linkSpecs, sources and mappings. As you can see,
currently the datasets have to be in a local directory. More
sophisticated data access will be implemented with the coming Data
Access Module.<br>
</p>
<h3>Configuration Properties</h3>
<p>In the LDIF configuration file you can specify a (Java) properties
file to further tweak certain parameters concerning the integration
execution. Here is a list with all properties that can be set at the
moment and the possible values for each property:<br>
</p>
<ul>
  <li>Specify if all input quads should also be included in the output
file or only the mapped/translated quads.Default: <span style="font-family: monospace;">mapped-only</span></li>
</ul>
<p>
</p>
<pre style="margin-left: 40px;"><span style="font-weight: bold;">output = all | mapped-only</span><br></pre>
<ul>
  <li>Specify if URIs should be rewritten to a common URI in regard to
the discovered links by the Identity Resolution Module. Default: <span style="font-family: monospace;">true</span></li>
</ul>
<pre style="margin-left: 40px;"><span style="font-weight: bold;">rewriteURIs = true | false</span><br></pre>
<ul>
  <li>
    <p>Specify the graph containing the provenance information. Quads
from this graph are only written to the final output dataset, but are
not further processed by the integration flow.Default: <span style="font-family: monospace;">http://www4.wiwiss.fu-berlin.de/ldif/provenance</span></p>
  </li>
</ul>
<pre style="margin-left: 40px;"><span style="font-weight: bold;">provenanceGraphURI = http://www4.wiwiss.fu-berlin.de/ldif/provenance</span><br></pre>
<ul>
  <li>Here you can choose how data is stored while it is being
processed. Regarding
the space vs. speed compromise, there are two solutions right now: A
pure in-memory solution and a solution based on Project Voldemort, a
key value store. Default: <span style="font-family: monospace;">In-Memory</span></li>
</ul>
<pre style="margin-left: 40px;"><span style="font-weight: bold;">entityBuilderType = in-memory | voldemort</span><br></pre>
<br>
<p><strong>Setting the storage type:<br>
</strong></p>
<p>Depending on your integration use case, especially the size of the
input datasets, you may choose different storage types in order to
increase execution speed or limit the memory foot print. Right now we
offer two solutions:<br>
</p>
<ul>
  <li>An in-memory solution, which keeps most of the data in-memory to
perform as fast as possible.</li>
  <li>A file backed solution with <a href="http://project-voldemort.com/">Project Voldemort</a> as storage
solution.</li>
</ul>
Config property file changes:<br>
<pre>entityBuilderType = Voldemort | In-memory<br></pre>
<p>If this property is not set, it defaults to the in-memory solution.<br>
</p>
If you want to use the Voldemort setup, you have to carry out the
following steps:<br>
<ol>
  <li>Download the latest Voldemort release from their <a href="https://github.com/voldemort/voldemort/downloads">Download</a>
site.</li>
  <li>Unpack it to a local directory. (the same machine you want to run
LDIF on)</li>
  <li>Copy <a href="resources/stores.xml">this stores.xml</a> file
into the VOLDEMORT/config/single_node_cluster/config directory -
overwriting the old one.</li>
  <li>And start the voldemort server like this from the voldemort root
directory:<br>
  </li>
</ol>
<pre style="margin-left: 40px;">bin/voldemort-server.sh config/single_node_cluster<br></pre>
<h2 id="development"><a name="code"></a>7. Source
Code and Development</h2>
<br>
<p>LDIF is hosted by <a href="http://www.assembla.com/spaces/ldif/wiki">Assembla.com</a>.
The latest source code is available from <strong>Todo: Generate
download including example data </strong></p>
<p>The framework can be used under the terms of the <a href="http://www.apache.org/licenses/LICENSE-2.0">Apache Software
License</a>.<br>
</p>
<h2><a name="feedback" id="feedback"></a>8. Support and Feedback </h2>
<p>&nbsp;</p>
<p>For questions and feedback please use the LDIF Google Group.
  <table border=0 style="background-color: #fff; padding: 5px;" cellspacing=0>
    <tr><td>
    <img src="http://groups.google.com/intl/en/images/logos/groups_logo_sm.gif"
           height=30 width=140 alt="Google Groups">
    </td></tr>
    <tr><td style="padding-left: 5px">
    <b>Subscribe to LDIF</b>
    </td></tr>
    <form action="http://groups.google.com/group/ldif/boxsubscribe">
    <input type=hidden name="hl" value="en">
    <tr><td style="padding-left: 5px;">
    Email: <input type=text name=email>
    <input type=submit name="sub" value="Subscribe">
    </td></tr>
  </form>
  <tr><td align=right>
    <a href="http://groups.google.com/group/ldif?hl=en">Visit this group</a>
  </td></tr>
</table>
</p>
<h2 id="relatedprojects"><a name="related"></a>9. References</h2>
<ul>
  <li>Tom Heath, Christian Bizer: <a href="http://www.morganclaypool.com/doi/abs/10.2200/S00334ED1V01Y201102WBE001">Linked
Data: Evolving the Web into a Global Data Space </a>. Synthesis
Lectures on the Semantic Web: Theory and Technology, Morgan &amp;
Claypool Publishers, ISBN <a href="http://www.amazon.com/Linked-Data-Synthesis-Lectures-Engineering/dp/1608454304/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1297846088&amp;sr=8-1">978160845431
    </a>, 2011 ( <a href="http://linkeddatabook.com/">Free HTML
version </a>).</li>
  <li>Christian Bizer, Andreas Schultz: <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/BizerSchultz-COLD-R2R-Paper.pdf">The
R2R Framework: Publishing and Discovering Mappings on the Web </a> ( <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/BizerSchultz-COLD-R2R-Talk.pdf">Slides
    </a>). 1st International Workshop on Consuming Linked Data (COLD
2010), Shanghai, November 2010. </li>
  <li>Julius Volz, Christian Bizer, Martin Gaedke, Georgi Kobilarov: <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/VolzBizerGaedkeKobilarov-ISWC2009-Silk.pdf">Discovering
and Maintaining Links on the Web of Data </a> ( <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/VolzBizerGaedkeKobilarov-ISWC2009-Silk-Talk.pdf">Slides
    </a>). International Semantic Web Conference (ISWC2009),
Westfields, USA, October 2009. </li>
  <li>Robert Isele, Anja Jentzsch, Christian Bizer: <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/IseleJentzschBizer-Silk-Cold2010.pdf">Silk
Server - Adding missing Links while consuming Linked Data </a> ( <a href="http://www.wiwiss.fu-berlin.de/en/institute/pwo/bizer/research/publications/IseleJentzschBizer-Silk-Cold2010-Talk.pdf">Slides
    </a>). 1st International Workshop on Consuming Linked Data (COLD
2010), Shanghai, November 2010. </li>
</ul>
<p>&nbsp;</p>
<h2><a name="acknowledgments"></a>10. Acknowledgments </h2>
<p>This work was supported in part by Vulcan Inc. as part of its <a href="http://www.projecthalo.com">Project Halo </a> and by the EU FP7
project <a href="http://lod2.eu/">LOD2 - Creating Knowledge out of
Interlinked Data </a> (Grant No. 257943). </p>
<p>&nbsp;</p>
<ol>
</ol>
<br>
</div>
</div>

</body></html>